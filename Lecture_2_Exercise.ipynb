{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjRBP75T_bNq"
   },
   "source": [
    "# Artificial Neural Networks - second lecture: The Batch Perceptron Convergence Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaO7FBB1JACm"
   },
   "source": [
    "Let's start by importing the necessay libraries to the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yHbLY9hJqyXT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random as rnd\n",
    "import matplotlib.pyplot as plt\n",
    "from Helper import datasets_Noisy_AND_gate\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riBpbKtyK54c"
   },
   "source": [
    "We consider the neuron's model illustrated by the figure below:\n",
    "\n",
    "<img src=\"Perceptron_1.png\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "We consider in the following the vectors of inputs and weights in the following form:\n",
    "\n",
    "$W=[b,w_1,w2]^T$\n",
    "\n",
    "$X=[1, x_1, x_2]^T$\n",
    "\n",
    "$v = W^T.X$\n",
    "\n",
    "$y = signum(v)$ has the values $\\{-1, +1\\} $\n",
    "\n",
    "In this program we will code the Batch version of the Perceptron convergence algorithm. we will write a code that compute:\n",
    "\n",
    "0- function **generate( )** to generate training and testing datasets,\n",
    "\n",
    "0- function **intialize( )** to initialize weights and bias,\n",
    "\n",
    "1- function **linear_combier( )** to compute the induced local field $v$,\n",
    "\n",
    "2- function **signum( )** to compute the output $y$,\n",
    "\n",
    "3- function **cost( )** to comput the cost function $J( W )$,\n",
    "\n",
    "4- function **gradient( )** to compute the gradient of the cost function $\\Delta J(W)$,\n",
    "\n",
    "5- function **update( )** to update the vector W,\n",
    "\n",
    "6- function **model( )** to build and train the model\n",
    "\n",
    "7- function **predict( )** to predict the class of given patterns\n",
    "\n",
    "PSD = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function generate\n",
    "def generate():\n",
    "    # returns:\n",
    "    # X_train a matrix (m x N)\n",
    "    # X_test a matrix (m x N1)\n",
    "    # Y_train a vector (1 x N)\n",
    "    # Y_test a vector (1 x N1)\n",
    "    X_train, X_test, Y_train, Y_test = datasets_Noisy_AND_gate(N = 1000, PSD = 0.04, test = True, valid = False)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (2, 800)\n",
      "Y_train.shap (1, 800)\n",
      "X_test.shape (2, 199)\n",
      "[[-0.02667382  0.20804942  0.05689384 -0.16051661  0.8682343   0.89481828\n",
      "  -0.00531702  0.18866897  0.87121983  0.02775562]\n",
      " [-0.0038127   1.27382569  0.96083174  0.16784462  0.15743851  1.35267969\n",
      "   0.75465359  0.91383112 -0.18320986  0.04223402]]\n",
      "[[-1. -1. -1. -1. -1.  1. -1. -1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = generate()\n",
    "print('X_train.shape',X_train.shape)\n",
    "print('Y_train.shap',Y_train.shape)\n",
    "print('X_test.shape', X_test.shape)\n",
    "print(X_train[:,0:10])\n",
    "print(Y_train[:,0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function intialization\n",
    "def initialize( m):\n",
    "    # m is the number of inputs - dimension of the input vector \n",
    "    # m+1 the dimension of vector W including the bias\n",
    "    # this function should return a column vector (m+1 x 1)\n",
    "    # your code starts here 1 line\n",
    "    #W = np.zeros((m+1, 1))\n",
    "    W = np.ones((m+1, 1))*0.1\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1]\n",
      " [0.1]\n",
      " [0.1]]\n"
     ]
    }
   ],
   "source": [
    "m = 2\n",
    "W = initialize(m)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer is:\n",
    "\n",
    "$W = [0.0, 0.0, 0.0]^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function linear_combiener\n",
    "def linear_combiner(W, X):\n",
    "    # inputs W (m+1 x 1), X(m+1 x N)\n",
    "    # The output should be a vector (1 x N)\n",
    "    \n",
    "    # your code starts here 1 line\n",
    "    V = np.dot(W.T, X)\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = [[3. 3. 3. 3. 3.]]\n"
     ]
    }
   ],
   "source": [
    "W = np.ones((3,1))\n",
    "X = np.ones((3,5))\n",
    "V = linear_combiner(W, X)\n",
    "print('V =', V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theright answer is :\n",
    "\n",
    "$V = [[3.0, 3.0, 3.0, 3.0, 3.0]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function signum\n",
    "def signum(x):\n",
    "    # the input is a vector (1 x N)\n",
    "    # the output should be a vector (1 x N)\n",
    "    \n",
    "    # your code starts here 1 line\n",
    "    y = np.sign(x)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y = [[ 1. -1.  1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "#X = np.random.randn(2,5)\n",
    "X = [[0.2, -0.6, 1.66, -1e3]]\n",
    "Y = signum(X)\n",
    "print('Y =', Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer is :\n",
    "\n",
    "$Y = [[1., -1.,  1., -1.]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function cost\n",
    "def cost(V, D):\n",
    "    # input V and D are vectors of dimensions (1 x N)\n",
    "    # the output is a scalar\n",
    "    \n",
    "    # your code starts here 3 lines\n",
    "    Y = np.sign(V)\n",
    "    error = Y-D\n",
    "    misclass = (error != 0)\n",
    "    \n",
    "    x = -np.sum(V * D * misclass)\n",
    "    \n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8999999999999999\n"
     ]
    }
   ],
   "source": [
    "V = np.array([[0.5, -0.6, 0.3, -0.12]])\n",
    "D = np.array([[1, 1, -1, -1]])\n",
    "print(cost(V,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good answer is :\n",
    "\n",
    "$J(W) = , -0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function gradient\n",
    "def gradient(X, V, D):\n",
    "    # inputs are :\n",
    "    # D desired output a vector (1 x N)\n",
    "    # V the induced local field vector (1x N)\n",
    "    # X matrix of training dataset (m+1 x N)\n",
    "    # the output should be a vector (m+1 x 1)\n",
    "    dim = (np.sign(V)-D)!=0\n",
    "    idx = dim[0]\n",
    "    Xp = X[:, idx]\n",
    "    if Xp.shape != (0,0):\n",
    "        on = np.ones((Xp.shape[0], 1))\n",
    "        Dp = np.multiply(on, D[dim])\n",
    "        grad = -np.sum(Xp*Dp,1, keepdims = True)\n",
    "        return grad\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02029548],\n",
       "       [0.07488641],\n",
       "       [0.62113876]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rnd.seed(0)\n",
    "X = np.random.rand(3,5)\n",
    "V = np.array([[0.5, -0.6, 0.3, -0.1, 0.8]])\n",
    "D = np.array([[1, 1, -1, 1, -1]])\n",
    "gradient(X,V,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,4) (3,12) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9432\\3579052231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrepmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9432\\441122595.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(X, V, D)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mDp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mDp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,4) (3,12) "
     ]
    }
   ],
   "source": [
    "#rnd.seed(0)\n",
    "from numpy.matlib import repmat\n",
    "X = np.random.rand(3,5)\n",
    "V = np.array([[0.5, -0.6, 0.3, -0.1, 0.8]])\n",
    "D = np.array([[1, 1, -1, 1, -1]])\n",
    "DD = repmat(D, X.shape[0],1)\n",
    "g = gradient(X,V,DD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function update\n",
    "def update(W, gradient, learning_rate = 0.2):\n",
    "    # inputs are:\n",
    "    # W weight vector (m+1 x1)\n",
    "    # gradient a vector (m+1 x 1)\n",
    "    # learning rate is a scalar\n",
    "    # this function returns a vector (m+1 x1)\n",
    "    # your code starts here 1 line\n",
    "    Delta_W = - learning_rate * gradient\n",
    "    W = W + Delta_W\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.ones((m+1,1))\n",
    "grad = np.ones(W.shape)\n",
    "grad[1, 0] *= -1\n",
    "update(W,grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correct answer is $W= [[0.8], [1.2], [0.8]]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function model\n",
    "def model(X, D, learning_rate = 0.1, epoch = 50):\n",
    "    # inputs:\n",
    "    # X matix of inputs (m x N)\n",
    "    # D desired output (1 x N)\n",
    "    # learning_rate is a positive scalar\n",
    "    # epoch is an positive integer, the number of times the perceptron convergence algorithm has been lunched \n",
    "    # output:\n",
    "    # the trained weights\n",
    "    # the cost vector (1 x N)\n",
    "    m, N = X.shape\n",
    "    X = np.concatenate((np.ones((1,N)), X), axis = 0)\n",
    "    J = np.zeros((1, epoch))\n",
    "    W = initialize(m)\n",
    "    for k in range(epoch):\n",
    "        # your code starts here 5-6 lines\n",
    "        V = linear_combiner(W, X)\n",
    "        Y = signum(V)\n",
    "        j = cost(V, D)\n",
    "        J[0, k] = j\n",
    "        grad = gradient(X,V,D)\n",
    "        W = update(W, grad, learning_rate)\n",
    "    \n",
    "    print(\"---------finish---------\")\n",
    "    return W, J\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m =2\n",
    "X_train, X_test, Y_train, Y_test = generate()\n",
    "W, J = model(X_train , Y_train, learning_rate = 0.1, epoch =20)\n",
    "plt.plot(J[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function predict\n",
    "def predict(X):\n",
    "    V = linear_combiner(W, X)\n",
    "    Y = signum(V)\n",
    "    return Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = X_test.shape[1]\n",
    "X = np.concatenate((np.ones((1,N_test)), X_test), axis = 0)\n",
    "P = predict(X)\n",
    "print('--------Done---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LU3yeOJ95pmW"
   },
   "source": [
    "Now let's try the perceptron when noisy inputs are presented. Try several values of the noise PSD and check the number of errors commtted :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yALcojPN54hk"
   },
   "source": [
    "Finally, you can calculate the number of errors committed by the perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWc0JGB86CLj",
    "outputId": "9dd4ec39-e93b-4802-b6d5-251a348167e5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9432\\1912317246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mErrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of errors {} \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'P' is not defined"
     ]
    }
   ],
   "source": [
    "Errors = np.sum(np.abs(P -Y_test))/2\n",
    "print(\"Number of errors {} \".format(Errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitle-TRY.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
